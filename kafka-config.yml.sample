---
integration_name: com.newrelic.kafka

instances:
  # This instance gives an example of autodiscovery of brokers with a bootstrap broker, which is the recommended configuration.
  - name: kafka-metrics-bootstrap-discovery
    command: metrics
    arguments:
      # A cluster name is required to uniquely identify this collection result in Insights
      cluster_name: "testcluster1"

      # Kafka API version to target. Defaults to 1.0.0, which will work for all post-1.0.0 versions.
      # It cannot be autodetected, so it must be set to the actual version in use in the cluster.
      # Some features and metrics are not available in versions older than 1.0.0.
      kafka_version: "1.0.0"

      # Use bootstrap broker for discovery. The integration will connect to a fixed broker, described below, and retrieve
      # all other brokers in the cluster from it.
      autodiscover_strategy: "bootstrap"

      # Bootstrap broker arguments. These configure a connection to a single broker. The rest of the brokers in the cluster
      # will be discovered using that connection.
      bootstrap_broker_host: "localhost"
      bootstrap_broker_kafka_port: 9092
      bootstrap_broker_kafka_protocol: PLAINTEXT # Currently support PLAINTEXT and SSL

      # Whne bootstrap broker is used for discovery, JMX credentials and port must be the same for all brokers.
      bootstrap_broker_jmx_port: 9999
      bootstrap_broker_jmx_user: admin
      bootstrap_broker_jmx_password: password

      # Setting this to true will make the integration retrieve data only from the broker configured as bootstrap,
      # and no other brokers will be discovered from it.
      # Users will typically want to set this to false (default), unless a different discovery mechanism, such as Docker
      # or Kubernetes, is used on top of the integration.
      local_only_collection: false

      # This field is used to toggle the collection of broker and topic metrics. This is on by default and should only be set to "false"
      # for the specific case where only producers/consumers are being monitored and "topic_mode" is set to "All".
      # Any other case this field can be omitted.
      collect_broker_topic_data: true

      # Below are the fields used to fine tune/toggle topic metric collection. Can be one of:
      # - "all", where all topics found in all brokers will be collected.
      # - "none", which will disable topic collection alltogether.
      # - "list", which allows a fixed list of topics to be defined as topic_list: '["topic1", "topic2"]'
      # - "regex", which allows to define a regex to select which topics will be monitored using topic_regex: 'topic\d+'
      #
      # topic_mode: "all"
      # topic_mode: "none"
      topic_mode: "regex"
      topic_regex: 'topic\d+'
      # topic_mode: "list"
      # topic_list: `["topic1", "topic2", "topic3"]`

      # Topic size can also be collected from brokers in the cluster. This operation is intensive and can take a while
      # to collect for a larger number of topics. It is recommended to only enable this feature when collecting topics
      # selectively, i.e. topic_mode is not "all" or a very permissive regex.
      # If the field is omitted it will default to false.
      collect_topic_size: false

    # Additionally, custom labels can be added to further identify your data
    labels:
      env: production
      role: kafka

  # This instance gives an example of autodiscovery of brokers with zookeeper
  - name: kafka-metrics-zookeeper-discovery
    command: metrics
    arguments:
      # A cluster name is required to uniquely identify this collection result in Insights
      cluster_name: "testcluster1"

      # Override the kafka API version to target. Defaults to 1.0.0, which will work for all post-1.0.0 versions. Older versions of the API may be missing features.
      kafka_version: "1.0.0"

      # How to find brokers. Either "bootstrap" or "zookeeper"
      autodiscover_strategy: "zookeeper"

      # A list of zookeeper hosts to discover brokers from.
      # Only required and used if `autodiscover_mechanism` is "zookeeper"
      #
      # The "zookeeper_hosts" field is a JSON array, each entry in the array connection information for a Zookeeper node.
      # Each entry should have the following fields:
      # - host: The IP or Hostname of a Zookeeper node, if the New Relic agent is installed on a Zookeeper node "localhost" is an acceptable value
      # - port: The port Zookeeper is listening on for incoming requests. If omitted, a default port of 2181 will be used.
      zookeeper_hosts: '[{"host": "localhost", "port": 2181}]'

      # If using "user" authentication, the credentials must be specified as a string of the form "<user>:<password>"
      # Example: 'zookeeperuser:zookeeperpass'
      zookeeper_auth_secret: "username:password"

      # If the Kafka configuration files are not in the root node of Zookeeper, an alternative root node can be specified.
      # The alternative root must have a leading slash.
      zookeeper_path: "/kafka-root"

      # It is common to use the same JMX configuration across a Kafka cluster
      # The default username and password are the credentials that will be used to make
      # a JMX connection to each broker found by Zookeeper. Theses values will also
      # be used when connecting to a consumer and/or producer if the "username" or "password"
      # field are omitted.
      default_jmx_user: "username"
      default_jmx_password: "password"

      # See above for more information on topic collection
      collect_broker_topic_data: true
      topic_mode: "all"
      collect_topic_size: false

    # Additionally, custom labels can be added to further identify your data
    labels:
      env: production
      role: kafka

  # Example configuration for collecting consumer offsets for the cluster
  - name: kafka-consumer-offsets
    command: consumer_offset
    arguments:
      cluster_name: "testcluster3"

      autodiscover_strategy: "bootstrap"
      bootstrap_broker_host: "localhost"
      bootstrap_broker_kafka_port: 9092
      bootstrap_broker_kafka_protocol: PLAINTEXT

      # A regex pattern that matches the consumer groups to collect metrics from
      consumer_group_regex: '.*'

  # Example configuration for collecting JMX metrics form consumers and producers.
  # Please note that we use JMX to collect these metrics, which means that only producers and consumers written in Java
  # are supported for collection.
  - name: kafka-producer-consumer-metrics
    command: metrics
    arguments:
      cluster_name: "testcluster3"

      # In order to collect Java producer and consumer metrics the "producers" and "consumers" fields should be filled out.
      # Both fields are JSON arrays with each entry being a separate JAVA producer or consumer, in it's respective field.
      # Each entry should have the following fields:
      # - name: This is the actual name of the producer/consumer as it appears in Kafka
      # - host: The IP or Hostname of the producer/consumser. If omitted, will use the value of the "default_jmx_host" field
      # - port: The port in which JMX is setup for on the producer/consumer. If omitted will, use the value of the "default_jmx_port" field
      # - username: The username used to connect to JMX. If omitted, will use the value of the "default_jmx_user" field
      # - password: The password used to connect to JMX. If omitted, will use the value of the "default_jmx_password" field
      # Example: {"name": "myProducer", "host": "localhost", "port": 24, "username": "me', "password": "secret"}
      producers: '[{"name": "myProducer", "host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
      consumers: '[{"name": "myConsumer", "host": "localhost", "port": 24, "username": "me", "password": "secret"}]'

      # If several producers/consumers are on the same host an agent can be installed on that host and the
      # "default_jmx_host" and "default_jmx_port" field can be set once and used for all producers/consumers that
      # do not have the "host" or "port" field repsectively.
      # These fields can be removed if each producer/consumer has it's own "host" and/or "port" field filled out.
      default_jmx_host: "localhost"
      default_jmx_port: "9999"

  - name: kafka-kerberos-auth
    command: metrics
    arguments:
      # A cluster name is required to uniquely identify this collection result in Insights
      cluster_name: "testcluster1"

      autodiscover_strategy: "bootstrap"

      # Bootstrap broker arguments. These configure a connection to a single broker. The rest of the brokers in the cluster
      # will be discovered using that connection.
      bootstrap_broker_host: "localhost"
      bootstrap_broker_kafka_port: 9092
      bootstrap_broker_kafka_protocol: PLAINTEXT # Currently support PLAINTEXT and SSL
      bootstrap_broker_jmx_port: 9999
      # JMX user and password default to `default_jmx_user` and `default_jmx_password` if unset
      bootstrap_broker_jmx_user: admin
      bootstrap_broker_jmx_password: password

      # Kerberos authentication arguments
      sasl_mechanism: GSSAPI
      sasl_gssapi_realm: SOMECORP.COM
      sasl_gssapi_service_name: Kafka
      sasl_gssapi_username: kafka
      sasl_gssapi_key_tab_path: /etc/newrelic-infra/kafka.keytab
      sasl_gssapi_kerberos_config_path: /etc/krb5.conf
      # disables FAST negotiation that causes issues with Active Directory
      # sasl_gssapi_disable_fast_negotiation: false

      # Only collect metrics from the bootstrap broker configured. The integration will not attempt to collect metrics
      # for any other broker, nor will it collect cluster-level metrics like topic metrics. This is useful for things
      # like deployment to kubernetes, where a single integration instance is desired per broker.
      local_only_collection: false

      # See above for more information on topic collection
      collect_broker_topic_data: true
      topic_mode: "all"
      collect_topic_size: false

  # This instance gives an example of collecting inventory with the integration
  - name: kafka-inventory
    command: inventory
    arguments:
      cluster_name: "testcluster2"
      zookeeper_hosts: '[{"host": "localhost", "port": 2181}]'
      zookeeper_auth_secret: "username:password"

      # Below are the fields used to fine tune/toggle topic inventory collection.
      # In order to collect topics the "topic_mode" field must be set to "all", "list", or "regex"
      topic_mode: 'all'
